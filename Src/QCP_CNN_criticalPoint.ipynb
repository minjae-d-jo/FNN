{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import sys\n",
    "# turn off GPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=8\n",
    "Tmin=3.00\n",
    "Tmax=9.00\n",
    "# Tmin=4.00\n",
    "# Tmax=8.00\n",
    "# en=8 #give an error\n",
    "en=10\n",
    "\n",
    "number_of_ensembles=500*en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_QCP = '/pds/pds132/ML/FNN/'\n",
    "file_QCP_image = path_QCP + 'QJMC_{L:d}/QJMC_AC_1000_{L:d}_{T:0.2f}_500_{en:d}.table'\n",
    "file_QCP_label = path_QCP + 'label/QJMC_AC_1000_12_{T:0.2f}_500_1_isOrdered.table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_training_files_for_each_phase = int(Tmin/0.04)\n",
    "number_of_training_files = 2 * number_of_training_files_for_each_phase\n",
    "NUM_TOTAL = number_of_ensembles*number_of_training_files\n",
    "NUM_TRAIN = int(NUM_TOTAL*0.9)\n",
    "NUM_VALID = NUM_TOTAL-NUM_TRAIN\n",
    "SHUFFLE_BUFFER_SIZE = 1500\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "def list_of_file(type_of_data, T_init, T_stop, e):\n",
    "    list = []\n",
    "    for T in np.arange(T_init, T_stop, 0.04):\n",
    "        list.append(type_of_data.format(L=L, T=T, en=e))\n",
    "    return list\n",
    "\n",
    "list_of_image=[]; list_of_label=[];\n",
    "for e in range(1, en+1):\n",
    "        list_of_image += list_of_file(file_QCP_image, 0.00, Tmin, e)\n",
    "        list_of_image += list_of_file(file_QCP_image, Tmax, 12.00, e)\n",
    "        list_of_label += list_of_file(file_QCP_label, 0.00, Tmin, e)\n",
    "        list_of_label += list_of_file(file_QCP_label, Tmax, 12.00, e)\n",
    "\n",
    "images = tf.data.Dataset.from_tensor_slices(list_of_image).interleave(tf.data.TextLineDataset, cycle_length=number_of_training_files, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "labels = tf.data.Dataset.from_tensor_slices(list_of_label).interleave(tf.data.TextLineDataset, cycle_length=number_of_training_files, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = tf.data.Dataset.zip((images, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training and validation\n",
    "dataset_train = dataset.take(NUM_TRAIN)\n",
    "dataset_valid = dataset.skip(NUM_TRAIN).take(NUM_VALID)\n",
    "# repeat and shuffle\n",
    "dataset_train = dataset_train.repeat().shuffle(SHUFFLE_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map and cache\n",
    "@tf.function\n",
    "def decoder(image, label):\n",
    "    image = tf.strings.split(image)\n",
    "    image = tf.strings.to_number(image, out_type = tf.float64)\n",
    "#     image = tf.reshape(image, shape = [-1])\n",
    "    label = tf.strings.split(label)\n",
    "    label = tf.strings.to_number(label, out_type = tf.float64)\n",
    "#     label = tf.reshape(label, shape = [-1])\n",
    "    return image, label\n",
    "\n",
    "dataset_train = dataset_train.map(decoder, num_parallel_calls = tf.data.experimental.AUTOTUNE).cache()\n",
    "dataset_valid = dataset_valid.map(decoder, num_parallel_calls = tf.data.experimental.AUTOTUNE).cache()\n",
    "\n",
    "# batch and prefetch\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder = True).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)\n",
    "dataset_valid = dataset_valid.batch(NUM_VALID).prefetch(buffer_size = tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.keras.Input(shape=L, dtype=tf.float64)\n",
    "x = tf.keras.layers.Reshape((L, 1)) (images)\n",
    "x = tf.keras.layers.Conv1D(128, 2, activation=tf.keras.activations.relu)(x)\n",
    "# x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.Conv1D(128, 2, activation=tf.keras.activations.relu)(x)\n",
    "# x = tf.keras.layers.Conv1D(256, 2, activation=tf.keras.activations.relu)(x)\n",
    "# x = tf.keras.layers.Conv1D(256, 2, activation=tf.keras.activations.relu)(x)\n",
    "# x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(int(np.power(L * L, 1.0)), activation=tf.keras.activations.relu, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
    "x = tf.keras.layers.Dense(int(np.power(L * L, 1.0)), activation=tf.keras.activations.relu)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(int(np.power(L * L, 0.9)), activation=tf.keras.activations.relu)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(int(np.power(L * L, 0.8)), activation=tf.keras.activations.relu)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(int(np.power(L * L, 0.7)), activation=tf.keras.activations.relu)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(int(np.power(L * L, 0.6)), activation=tf.keras.activations.relu)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(int(np.power(L * L, 0.5)), activation=tf.keras.activations.relu)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "labels = tf.keras.layers.Dense(2, activation=tf.keras.activations.softmax)(x)\n",
    "\n",
    "cnn = tf.keras.Model(images, labels)\n",
    "# cnn.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "#         loss=tf.keras.losses.MeanSquaredError(),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=['accuracy'])\n",
    "cnn.summary()\n",
    "tf.keras.utils.plot_model(cnn, \n",
    "                          to_file='dataTensorFlow_ising.png',\n",
    "                          show_shapes=True,\n",
    "                          show_layer_names=False,\n",
    "                          rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_history = cnn.fit(dataset_train,\n",
    "                      verbose=1,\n",
    "                    #   epochs=30,\n",
    "                    #   epochs=25,\n",
    "                    #   epochs=35,\n",
    "                       epochs=5,\n",
    "                    #   epochs=1,\n",
    "                      steps_per_epoch=int(NUM_TRAIN/BATCH_SIZE),\n",
    "                      validation_data=dataset_valid,\n",
    "                      validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, filename):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.clf()\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(hist['epoch'], hist['accuracy'], label='Train')\n",
    "    plt.plot(hist['epoch'], hist['val_accuracy'], label = 'Validation')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(hist['epoch'], hist['loss'], label='Train')\n",
    "    plt.plot(hist['epoch'], hist['val_loss'], label = 'Validation')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "\n",
    "save = '/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/RNN/Saves/QCP4_{L:d}_{Tmin:0.2f}_{Tmax:0.2f}_{en:d}_save.h5'\n",
    "struct = '/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/RNN/Saves/QCP4_{L:d}_{Tmin:0.2f}_{Tmax:0.2f}_{en:d}_struct.png'\n",
    "train_history = '/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/RNN/Saves/QCP4_{L:d}_{Tmin:0.2f}_{Tmax:0.2f}_{en:d}_history.pdf'\n",
    "\n",
    "tf.keras.utils.plot_model(cnn, to_file = struct.format(L = L, Tmin = Tmin, Tmax = Tmax, en = en), show_shapes = True, show_layer_names = False, rankdir = 'LR')\n",
    "cnn.save(save.format(L = L, Tmin = Tmin, Tmax = Tmax, en = en))\n",
    "plot_history(cnn_history, train_history.format(L = L, Tmin = Tmin, Tmax = Tmax, en = en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_QCP_TEST_image = path_QCP + 'QJMC_{L:d}/QJMC_AC_1000_{L:d}_{T:0.2f}_500_{en:d}.table'\n",
    "number_of_test_files = int((Tmax-Tmin)/0.04)\n",
    "number_of_total_files=number_of_test_files+number_of_training_files   \n",
    "      \n",
    "list_of_image=[]; list_of_label=[];\n",
    "for e in range(1, en+1):\n",
    "    list_of_image += list_of_file(file_QCP_image, 0.00, 12.00, e)\n",
    "    list_of_label += list_of_file(file_QCP_label, 0.00, 12.00, e)\n",
    "\n",
    "images = tf.data.Dataset.from_tensor_slices(list_of_image).interleave(tf.data.TextLineDataset, cycle_length=number_of_total_files, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "labels = tf.data.Dataset.from_tensor_slices(list_of_label).interleave(tf.data.TextLineDataset, cycle_length=number_of_total_files, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset = tf.data.Dataset.zip((images, labels))\n",
    "\n",
    "\n",
    "# map and caching\n",
    "@tf.function\n",
    "def decoder(image, label):\n",
    "    image = tf.strings.split(image)\n",
    "    image = tf.strings.to_number(image, out_type = tf.float64)\n",
    "#     image = tf.reshape(image, shape = [-1])\n",
    "    label = tf.strings.split(label)\n",
    "    label = tf.strings.to_number(label, out_type = tf.float64)\n",
    "    return image, label\n",
    "\n",
    "dataset = dataset.map(decoder, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "dataset = dataset.batch(number_of_total_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cnn.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.zeros((number_of_total_files, 2))\n",
    "\n",
    "NUM_TEST=int(number_of_ensembles * number_of_total_files)\n",
    "\n",
    "for i in range(NUM_TEST):\n",
    "    outputs[i%(number_of_total_files)] += output[i]\n",
    "outputs/=(NUM_TEST/(number_of_total_files))\n",
    "fig = plt.figure()\n",
    "Tc=6.0\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Output Layer')\n",
    "plt.axvspan(0.0, Tmin, color = 'C0', alpha = 0.3)\n",
    "plt.axvspan(Tmin+number_of_test_files*0.04, 12.00, color = 'C3', alpha = 0.3)\n",
    "\n",
    "plt.axvline(x = Tc, ls='--', color = 'C0', linewidth=2)\n",
    "plt.axhline(0.5, ls='--', color = 'C0', linewidth=2)\n",
    "\n",
    "outputs_withT = np.zeros(((number_of_total_files), 3))\n",
    "for i in range(number_of_total_files):\n",
    "    T = 0 + 0.04 * i\n",
    "    outputs_withT[i][0] = T\n",
    "    outputs_withT[i][1] = outputs[i][0]\n",
    "    outputs_withT[i][2] = outputs[i][1]\n",
    "     \n",
    "plt.plot([outputs_withT[i][0] for i in range(number_of_total_files)], [outputs_withT[i][1] for i in range(number_of_total_files)])\n",
    "plt.plot([outputs_withT[i][0] for i in range(number_of_total_files)], [outputs_withT[i][2] for i in range(number_of_total_files)])\n",
    "\n",
    "fig = '/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/RNN/Results/QCP4_{L:d}_{Tmin:0.2f}_{Tmax:0.2f}_{en:d}.pdf'\n",
    "plt.savefig(fig.format(L = L, Tmin = Tmin, Tmax = Tmin+number_of_test_files*0.04, en = en))\n",
    "\n",
    "dat = '/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/RNN/Results/QCP4_{L:d}_{Tmin:0.2f}_{Tmax:0.2f}_{en:d}.table'\n",
    "np.savetxt(dat.format(L = L,  Tmin = Tmin, Tmax = Tmin+number_of_test_files*0.04, en = en), outputs_withT, fmt = \"%f\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import matplotlib as mpl\n",
    "plt.figure()\n",
    "Tc=6.0\n",
    "Tmin=3.0\n",
    "Tmax=9.0\n",
    "plt.xlabel('Quantum coherence')\n",
    "plt.ylabel('Output Layer')\n",
    "plt.axvspan(0.0, Tmin, color = 'C0', alpha = 0.3)\n",
    "plt.axvspan(Tmax, 12.00, color = 'C3', alpha = 0.3)\n",
    "\n",
    "plt.axvline(x = Tc, ls='--', color = 'C0', linewidth=2)\n",
    "plt.axhline(0.5, ls='--', color = 'C0', linewidth=2)\n",
    "\n",
    "# f = open('%s.csv' % name, 'wb')/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/FNN/Results/\n",
    "filename_test='/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/RNN/Results/QCP4_{L:d}_{Tmin:0.2f}_{Tmax:0.2f}_{en:d}.table'\n",
    "# cmap = mpl.cm.autumn\n",
    "colors = [\"red\", \"orange\", \"blue\", \"green\", \"purple\", \"yellow\", \"black\",\"red\", \"orange\", \"blue\", \"green\", \"purple\", \"yellow\", \"black\"]\n",
    "\n",
    "\n",
    "X, Y, Z = [], [], []\n",
    "for M in range(8, 17, 2):\n",
    "    for line in open(filename_test.format(L = M, Tmin = Tmin, Tmax = Tmax, en = en), 'r'):\n",
    "        values = [float(s) for s in line.split()]\n",
    "        X.append(values[0])\n",
    "        Y.append(values[1])  \n",
    "        Z.append(values[2])  \n",
    "    plt.plot(X, Y, color='{col:s}'.format(col = colors[M-8]), label='{L:d}'.format(L = M))\n",
    "    plt.plot(X, Z, color='{col:s}'.format(col = colors[M-8]))\n",
    "    X, Y, Z = [], [], []\n",
    "plt.legend()\n",
    "\n",
    "X, Y, Z = [], [], []\n",
    "for line in open('/pds/pds181/jmj/JupyterLab/Project_QCP_criticalPoint/RNN/Results/QCP4_18_4.00_8.00_10.table', 'r'):\n",
    "    values = [float(s) for s in line.split()]\n",
    "    X.append(values[0])\n",
    "    Y.append(values[1])  \n",
    "    Z.append(values[2])  \n",
    "plt.plot(X,Y, color='g', label='18')\n",
    "plt.plot(X,Z, color='g')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32d063cde35d815303a8d947f850d47dfc0056ffbac25a4832b956260cb9513a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('JointProbDist': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
